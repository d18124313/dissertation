{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "## @see https://www.kaggle.com/toorkp/churn-wsdm/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "init_cell": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import gc; gc.enable()\n",
    "import time\n",
    "import sys\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_curve, auc, confusion_matrix, f1_score, log_loss, confusion_matrix\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "from scipy.stats import randint as sp_randint\n",
    "\n",
    "from collections import Counter\n",
    "from numpy.random import RandomState\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "pd.options.display.float_format = \"{:.2f}\".format\n",
    "np.set_printoptions(precision=4)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "sys.path.append('modules')\n",
    "\n",
    "from shared_functions import *\n",
    "import pickle\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load the pre-split data\n",
    "\n",
    "store = pd.HDFStore('/home/dissertation/data/dfs_abt_split.h5')\n",
    "X_train = store['X_train']\n",
    "X_test = store['X_test']\n",
    "y_train = store['y_train']\n",
    "y_test = store['y_test']\n",
    "store.close()\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)\n",
    "\n",
    "cat_col= ['gender', 'city', 'registered_via']\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train.columns[0:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ## TEMP TEMP TEMP ##\n",
    "# for col in X_train.head().filter(regex='daily').columns:\n",
    "#     X_train.drop(col, axis=1, inplace=True)\n",
    "#     X_test.drop(col, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sklearn \n",
    "sklearn.metrics.SCORERS.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## WHAT METRIC SHOULD BE OPTIMSED AS PART OF CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42 \n",
    "CV_ITER = 5\n",
    "SCORING_METRIC = 'recall'\n",
    "BASE_NAME = \"dfsbasic_\" + str(CV_ITER) + \"cv_\" + SCORING_METRIC\n",
    "\n",
    "## Each entry in the list is a Tuple of\n",
    "##   [ModelName, Model, HyperParams, ScoringMetric]\n",
    "classifiers = [\n",
    "    ('NB_' + BASE_NAME, GaussianNB(), {}, SCORING_METRIC),\n",
    "#     ('DT_' + BASE_NAME, DecisionTreeClassifier(), {}, SCORING_METRIC),\n",
    "#     ('RF_' + BASE_NAME, RandomForestClassifier(n_jobs =-1), {}, SCORING_METRIC),\n",
    "#     ('LR_' + BASE_NAME, LogisticRegression(solver = 'liblinear'), {}, SCORING_METRIC),\n",
    "#     ('AB_' + BASE_NAME, AdaBoostClassifier(), {}, SCORING_METRIC),\n",
    "#     ('MLP_' + BASE_NAME, MLPClassifier(), {}, SCORING_METRIC),\n",
    "#     ('XGB_' + BASE_NAME, xgb.XGBClassifier(objective=\"binary:logistic\"), {}, SCORING_METRIC) \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_metrics = pd.DataFrame()\n",
    "all_results = list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1.1 Baseline - Default Settings - No sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "sampler = ('None', DummySampler())\n",
    "\n",
    "exp_metrics, model_results = perform_experiment(X_train, X_test, y_train, y_test, classifiers, sampler, 1, \\\n",
    "                                                cv_iter=CV_ITER, cat_col=cat_col)\n",
    "\n",
    "all_metrics = all_metrics.append(exp_metrics)\n",
    "all_results.append((sampler[0]+\"_\"+BASE_NAME, exp_metrics, model_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1.2 Baseline - Default Settings - Oversampled training set 100%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "sampler = ('ROS 1:1', RandomOverSampler(random_state=RANDOM_STATE))\n",
    "\n",
    "exp_metrics, model_results = perform_experiment(X_train, X_test, y_train, y_test, classifiers, sampler, 1, \\\n",
    "                                                cv_iter=CV_ITER, cat_col=cat_col)\n",
    "\n",
    "all_metrics = all_metrics.append(exp_metrics)\n",
    "all_results.append((sampler[0]+\"_\"+BASE_NAME, exp_metrics, model_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1.3 Baseline - Default Settings - Undersampled training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = ('RUS 1:1', RandomUnderSampler(random_state=RANDOM_STATE))\n",
    "\n",
    "exp_metrics, model_results = perform_experiment(X_train, X_test, y_train, y_test, classifiers, sampler, 1, \\\n",
    "                                                cv_iter=CV_ITER, cat_col=cat_col)\n",
    "\n",
    "all_metrics = all_metrics.append(exp_metrics)\n",
    "all_results.append((sampler[0]+\"_\"+BASE_NAME, exp_metrics, model_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1.4 Baseline - Default Settings - Over sampling - 33% of majority size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = ('ROS 3:1', RandomOverSampler(random_state=RANDOM_STATE, sampling_strategy = 1/3))\n",
    "\n",
    "exp_metrics, model_results = perform_experiment(X_train, X_test, y_train, y_test, classifiers, sampler, 1, \\\n",
    "                                                cv_iter=CV_ITER, cat_col=cat_col)\n",
    "\n",
    "all_metrics = all_metrics.append(exp_metrics)\n",
    "all_results.append((sampler[0]+\"_\"+BASE_NAME, exp_metrics, model_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1.5 Baseline - Default Settings - Over sampling - 66% of majority size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = ('ROS 3:2', RandomOverSampler(random_state=RANDOM_STATE, sampling_strategy = 2/3))\n",
    "\n",
    "exp_metrics, model_results = perform_experiment(X_train, X_test, y_train, y_test, classifiers, sampler, 1, \\\n",
    "                                                cv_iter=CV_ITER, cat_col=cat_col)\n",
    "\n",
    "all_metrics = all_metrics.append(exp_metrics)\n",
    "all_results.append((sampler[0]+\"_\"+BASE_NAME, exp_metrics, model_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1.6 Baseline - Default Settings - Over sampling - 50% of majority size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = ('ROS 2:1', RandomOverSampler(random_state=RANDOM_STATE, sampling_strategy = 1/2))\n",
    "\n",
    "exp_metrics, model_results = perform_experiment(X_train, X_test, y_train, y_test, classifiers, sampler, 1, \\\n",
    "                                                cv_iter=CV_ITER, cat_col=cat_col)\n",
    "\n",
    "all_metrics = all_metrics.append(exp_metrics)\n",
    "all_results.append((sampler[0]+\"_\"+BASE_NAME, exp_metrics, model_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1.7 Baseline Default Settings SMOTE-NC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sampler = ('SMOTE_NC', SMOTENC(random_state=RANDOM_STATE, categorical_features=[0,1,2,3,4,5,6,7,8,13,14], n_jobs=8))\n",
    "\n",
    "## Keep the following, essentially dropping the dt columns\n",
    "cols = ['is_churn', 'city', 'gender', 'age_cat', 'registered_via', 'total_order',\n",
    "       'payment_method_id_mode', 'payment_method_id_count',\n",
    "       'payment_plan_days_mode', 'payment_plan_days_mean',\n",
    "       'plan_list_price_mean', 'plan_lifetime_value', 'actual_amount_mean',\n",
    "       'total_actual_amount', 'is_auto_renew_mode', 'cancel_times','transaction_date_delta']\n",
    "\n",
    "exp_metrics, model_results = perform_experiment(X_train, X_test, y_train, y_test, classifiers, sampler, 1, \\\n",
    "                                                cv_iter=CV_ITER, cat_col=cat_col)\n",
    "\n",
    "all_metrics = all_metrics.append(exp_metrics)\n",
    "all_results.append((sampler[0]+\"_\"+BASE_NAME, exp_metrics, model_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Persist results to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store(all_results, 'DFS_Default_{0}.pickle'.format(datetime.today().strftime('%Y-%m-%d')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort the results and get the best sampling config per classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_results = all_metrics.sort_values(['balanced_accuracy'], ascending=[False]).groupby('classifier').head(1)\n",
    "top_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph the results base on the list of best classifiers above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = filter_top_model_results(top_results, all_results)\n",
    "plot_roc_prc(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Just try an SVM \n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model_train_results = train_model(base_dataset, sampling_method = 'under', classifiers = [('SGDClassifier', SGDClassifier(loss='log'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Print the feature importance \n",
    "\n",
    "feature_index = np.flip(np.argsort(model.feature_importances_), axis=0)\n",
    "ordered_features = []\n",
    "column_names = X_test.columns\n",
    "\n",
    "for i in feature_index[0:10]:\n",
    "    print(np.round(model.feature_importances_[i], 3), ' --> ', column_names[i])\n",
    "    ordered_features.append(column_names[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Print the permutation importance \n",
    "\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "\n",
    "_, X_test, _, y_test = prepare_train_test_split(model_dataset, 0)\n",
    "\n",
    "perm = PermutationImportance(model, random_state=1).fit(X_test, y_test)\n",
    "\n",
    "eli5.show_weights(perm, feature_names = X_test.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_name, model = model_train_results[1][2]\n",
    "\n",
    "for model_name, model in model_train_results[1]:\n",
    "    probs = model.predict_proba(X_test)[:, 1]\n",
    "    pr_data = plot_precision_recall(\n",
    "        y_test, probs, title='PR Curve for {0}'.format(model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = model.predict_proba(X_test)[:, 1]\n",
    "pr_data = plot_precision_recall(\n",
    "    y_test, probs, title='PR Curve for {0}'.format(model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_data = plot_roc(\n",
    "    y_test, probs, title='ROC Curve for {0}'.format(model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(plt.style.available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Original Data distribution\")\n",
    "print(model_dataset['is_churn'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display new class counts\n",
    "print('Sci-Kit Learn : resample : Down Sampled data set')\n",
    "train_downsample = undersampled_dataset(model_dataset, 'is_churn')\n",
    "\n",
    "print(train_downsample['is_churn'].value_counts())\n",
    "print(\"Num records = \", train_downsample.shape[0])\n",
    "train_downsample.is_churn.value_counts().plot(kind='bar', title='Count (target)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display new class counts\n",
    "print('Sci-Kit Learn : resample : Up Sampled data set')\n",
    "train_upsample = oversampled_dataset(model_dataset, 'is_churn')\n",
    "\n",
    "print(train_upsample['is_churn'].value_counts())\n",
    "print(\"Num records = \", train_upsample.shape[0])\n",
    "train_upsample.is_churn.value_counts().plot(kind='bar', title='Count (target)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "probs = model.predict_proba(X_test)[:, 1]\n",
    "pr_data = plot_precision_recall(\n",
    "    y_test, probs, title='Precision-Recall Curve for Random Forest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_above = pr_data.loc[pr_data['precision'] >= 0.25].copy()\n",
    "precision_above.sort_values('recall', ascending=False, inplace=True)\n",
    "precision_above.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "threshold_required = 0.5\n",
    "# Make predictions where probability is above threshold\n",
    "preds = np.zeros(len(y_test))\n",
    "preds[probs >= threshold_required] = 1\n",
    "\n",
    "# Make and plot confusion matrix\n",
    "cm = confusion_matrix(y_test, preds)\n",
    "plot_confusion_matrix(cm, classes=['No Churn', 'Churn'],\n",
    "                      title='Churn Confusion Matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi = pd.DataFrame({'importance': model.feature_importances_}, index=model_dataset.iloc[:, 1:].columns).\\\n",
    "    sort_values('importance', ascending=False)\n",
    "fi.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
