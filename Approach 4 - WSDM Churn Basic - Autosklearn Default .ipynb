{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "## @see https://www.kaggle.com/toorkp/churn-wsdm/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "init_cell": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import gc; gc.enable()\n",
    "import time\n",
    "import sys\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_curve, auc, confusion_matrix, f1_score, log_loss, confusion_matrix\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from collections import Counter\n",
    "from numpy.random import RandomState\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "pd.options.display.float_format = \"{:.2f}\".format\n",
    "np.set_printoptions(precision=4)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "sys.path.append('modules')\n",
    "\n",
    "from shared_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dataset = pd.read_hdf('/home/dissertation/data/base_abt.h5', 'base_abt')\n",
    "\n",
    "base_dataset['city'] = base_dataset.city.astype(str)\n",
    "base_dataset['registered_via'] = base_dataset.registered_via.astype(str)\n",
    "\n",
    "## Simple Data Prep \n",
    "base_dataset = base_dataset.drop(labels =['gender','msno'], axis=1)\n",
    "\n",
    "## Simply drops records with NA \n",
    "base_dataset = clean_dataset(base_dataset)\n",
    "\n",
    "print(base_dataset.shape)\n",
    "base_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42 \n",
    "CV_ITER = 3\n",
    "SCORING_METRIC = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-e4c548316611>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mall_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mall_metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "all_metrics = pd.DataFrame()\n",
    "all_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_dataset = base_dataset.sample(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import autosklearn.classification\n",
    "import sklearn.model_selection\n",
    "import sklearn.datasets\n",
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = \\\n",
    "            prepare_train_test_split(base_dataset, \n",
    "                                     base_dataset.columns.get_loc(\"is_churn\"), \n",
    "                                     sampler = DummySampler(), \n",
    "                                     split_ratio = 0.7, \n",
    "                                     r_state = RANDOM_STATE,\n",
    "                                     cat_col = ['city','registered_via'])\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "y_train.is_churn.value_counts().plot(kind='bar', title='Train Set - Count (target)')\n",
    "plt.subplot(1, 2, 2)\n",
    "y_test.is_churn.value_counts().plot(kind='bar', title='Test Set - Count (target)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "automl = autosklearn.classification.AutoSklearnClassifier(time_left_for_this_task=int(3600*4), n_jobs=8)\n",
    "automl.fit(X_train.drop(columns=['registration_init_time', 'registration_init_time_dt'], axis=1), \n",
    "           y_train,\n",
    "          metric = autosklearn.metrics.precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = automl.predict(X_test.drop(columns=['registration_init_time', 'registration_init_time_dt'], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy score\", sklearn.metrics.accuracy_score(y_test, y_hat))\n",
    "print(\"Recall score\", sklearn.metrics.recall_score(y_test, y_hat))\n",
    "print(\"Accuracy score\", sklearn.metrics.accuracy_score(y_test, y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl.sprint_statistics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1.1 Baseline - Default Settings - No sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "sampler = ('None', DummySampler())\n",
    "\n",
    "exp_metrics = perform_experiment(base_dataset, classifiers, sampler, 1, RANDOM_STATE, cv_iter=CV_ITER)\n",
    "\n",
    "all_metrics = all_metrics.append(exp_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics.sort_values('f1_score', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1.2 Baseline - Default Settings - Oversampled training set 100%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sampler = ('ROS 1:1', RandomOverSampler(random_state=RANDOM_STATE))\n",
    "\n",
    "exp_metrics = perform_experiment(base_dataset, classifiers, sampler, 1, RANDOM_STATE, cv_iter=CV_ITER)\n",
    "\n",
    "all_metrics = all_metrics.append(exp_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1.3 Baseline - Default Settings - Undersampled training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = ('RUS 1:1', RandomUnderSampler(random_state=RANDOM_STATE))\n",
    "\n",
    "exp_metrics = perform_experiment(base_dataset, classifiers, sampler, 1, RANDOM_STATE, cv_iter=CV_ITER)\n",
    "\n",
    "all_metrics = all_metrics.append(exp_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1.4 Baseline - Default Settings - Over sampling - 33% of majority size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = ('ROS 3:1', RandomOverSampler(random_state=RANDOM_STATE, sampling_strategy = 1/3))\n",
    "\n",
    "exp_metrics = perform_experiment(base_dataset, classifiers, sampler, 1, RANDOM_STATE, cv_iter=CV_ITER)\n",
    "\n",
    "all_metrics = all_metrics.append(exp_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1.5 Baseline - Default Settings - Over sampling - 66% of majority size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = ('ROS 3:2', RandomOverSampler(random_state=RANDOM_STATE, sampling_strategy = 2/3))\n",
    "\n",
    "exp_metrics = perform_experiment(base_dataset, classifiers, sampler, 1, RANDOM_STATE, cv_iter=CV_ITER)\n",
    "\n",
    "all_metrics = all_metrics.append(exp_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1.6 Baseline - Default Settings - Over sampling - 50% of majority size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = ('ROS 2:1', RandomOverSampler(random_state=RANDOM_STATE, sampling_strategy = 1/2))\n",
    "\n",
    "exp_metrics = perform_experiment(base_dataset, classifiers, sampler, 1, RANDOM_STATE, cv_iter=CV_ITER)\n",
    "\n",
    "all_metrics = all_metrics.append(exp_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1.7 Baseline Default Settings SMOTE-NC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sampler = ('SMOTE_NC', SMOTENC(random_state=RANDOM_STATE, categorical_features=[0,1,2,3,4,5,6,7,12,13], n_jobs=8))\n",
    "\n",
    "## Keep the following, essentially dropping the dt columns\n",
    "cols = ['is_churn', 'city', 'bd', 'registered_via', 'total_order',\n",
    "       'payment_method_id_mode', 'payment_method_id_count',\n",
    "       'payment_plan_days_mode', 'payment_plan_days_mean',\n",
    "       'plan_list_price_mean', 'plan_lifetime_value', 'actual_amount_mean',\n",
    "       'total_actual_amount', 'is_auto_renew_mode', 'cancel_times']\n",
    "\n",
    "exp_metrics = perform_experiment(base_dataset[cols], classifiers, sampler, 1, RANDOM_STATE, cv_iter=CV_ITER)\n",
    "\n",
    "all_metrics = all_metrics.append(exp_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics.sort_values('aucroc', ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Just try an SVM \n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model_train_results = train_model(base_dataset, sampling_method = 'under', classifiers = [('SGDClassifier', SGDClassifier(loss='log'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Print the feature importance \n",
    "\n",
    "feature_index = np.flip(np.argsort(model.feature_importances_), axis=0)\n",
    "ordered_features = []\n",
    "column_names = X_test.columns\n",
    "\n",
    "for i in feature_index[0:10]:\n",
    "    print(np.round(model.feature_importances_[i], 3), ' --> ', column_names[i])\n",
    "    ordered_features.append(column_names[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Print the permutation importance \n",
    "\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "\n",
    "_, X_test, _, y_test = prepare_train_test_split(model_dataset, 0)\n",
    "\n",
    "perm = PermutationImportance(model, random_state=1).fit(X_test, y_test)\n",
    "\n",
    "eli5.show_weights(perm, feature_names = X_test.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_name, model = model_train_results[1][2]\n",
    "\n",
    "for model_name, model in model_train_results[1]:\n",
    "    probs = model.predict_proba(X_test)[:, 1]\n",
    "    pr_data = plot_precision_recall(\n",
    "        y_test, probs, title='PR Curve for {0}'.format(model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = model.predict_proba(X_test)[:, 1]\n",
    "pr_data = plot_precision_recall(\n",
    "    y_test, probs, title='PR Curve for {0}'.format(model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_data = plot_roc(\n",
    "    y_test, probs, title='ROC Curve for {0}'.format(model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(plt.style.available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Original Data distribution\")\n",
    "print(model_dataset['is_churn'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display new class counts\n",
    "print('Sci-Kit Learn : resample : Down Sampled data set')\n",
    "train_downsample = undersampled_dataset(model_dataset, 'is_churn')\n",
    "\n",
    "print(train_downsample['is_churn'].value_counts())\n",
    "print(\"Num records = \", train_downsample.shape[0])\n",
    "train_downsample.is_churn.value_counts().plot(kind='bar', title='Count (target)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display new class counts\n",
    "print('Sci-Kit Learn : resample : Up Sampled data set')\n",
    "train_upsample = oversampled_dataset(model_dataset, 'is_churn')\n",
    "\n",
    "print(train_upsample['is_churn'].value_counts())\n",
    "print(\"Num records = \", train_upsample.shape[0])\n",
    "train_upsample.is_churn.value_counts().plot(kind='bar', title='Count (target)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "probs = model.predict_proba(X_test)[:, 1]\n",
    "pr_data = plot_precision_recall(\n",
    "    y_test, probs, title='Precision-Recall Curve for Random Forest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_above = pr_data.loc[pr_data['precision'] >= 0.25].copy()\n",
    "precision_above.sort_values('recall', ascending=False, inplace=True)\n",
    "precision_above.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "threshold_required = 0.5\n",
    "# Make predictions where probability is above threshold\n",
    "preds = np.zeros(len(y_test))\n",
    "preds[probs >= threshold_required] = 1\n",
    "\n",
    "# Make and plot confusion matrix\n",
    "cm = confusion_matrix(y_test, preds)\n",
    "plot_confusion_matrix(cm, classes=['No Churn', 'Churn'],\n",
    "                      title='Churn Confusion Matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi = pd.DataFrame({'importance': model.feature_importances_}, index=model_dataset.iloc[:, 1:].columns).\\\n",
    "    sort_values('importance', ascending=False)\n",
    "fi.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
