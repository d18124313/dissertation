{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "## @see https://www.kaggle.com/toorkp/churn-wsdm/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "init_cell": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import gc; gc.enable()\n",
    "import time\n",
    "import sys\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_curve, auc, confusion_matrix, f1_score, log_loss, confusion_matrix\n",
    "\n",
    "from collections import Counter\n",
    "from numpy.random import RandomState\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "pd.options.display.float_format = \"{:.2f}\".format\n",
    "np.set_printoptions(precision=4)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "sys.path.append('modules')\n",
    "\n",
    "from shared_functions import *\n",
    "import pickle\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Shape: (600803, 164) (600803,)\n",
      "Train Shape: (257487, 164) (257487,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bd</th>\n",
       "      <th>city</th>\n",
       "      <th>gender</th>\n",
       "      <th>registered_via</th>\n",
       "      <th>SUM(transactions.payment_plan_days)</th>\n",
       "      <th>SUM(transactions.plan_list_price)</th>\n",
       "      <th>SUM(transactions.actual_amount_paid)</th>\n",
       "      <th>SUM(transactions.transaction_date)</th>\n",
       "      <th>SUM(transactions.membership_expire_date)</th>\n",
       "      <th>SUM(transactions.price_difference)</th>\n",
       "      <th>...</th>\n",
       "      <th>DIFF(MAX(transactions.planned_daily_price))</th>\n",
       "      <th>DIFF(MAX(transactions.daily_price))</th>\n",
       "      <th>DIFF(STD(transactions.payment_plan_days))</th>\n",
       "      <th>DIFF(STD(transactions.plan_list_price))</th>\n",
       "      <th>DIFF(STD(transactions.actual_amount_paid))</th>\n",
       "      <th>DIFF(STD(transactions.transaction_date))</th>\n",
       "      <th>DIFF(STD(transactions.membership_expire_date))</th>\n",
       "      <th>DIFF(STD(transactions.price_difference))</th>\n",
       "      <th>DIFF(STD(transactions.planned_daily_price))</th>\n",
       "      <th>DIFF(STD(transactions.daily_price))</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>551174</th>\n",
       "      <td>28</td>\n",
       "      <td>5</td>\n",
       "      <td>male</td>\n",
       "      <td>3</td>\n",
       "      <td>180</td>\n",
       "      <td>298.00</td>\n",
       "      <td>894.00</td>\n",
       "      <td>120923653</td>\n",
       "      <td>120924153</td>\n",
       "      <td>428.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.67</td>\n",
       "      <td>1.67</td>\n",
       "      <td>0.00</td>\n",
       "      <td>76.94</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3890.64</td>\n",
       "      <td>3353.08</td>\n",
       "      <td>55.25</td>\n",
       "      <td>2.56</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403333</th>\n",
       "      <td>20</td>\n",
       "      <td>13</td>\n",
       "      <td>male</td>\n",
       "      <td>3</td>\n",
       "      <td>127</td>\n",
       "      <td>627.00</td>\n",
       "      <td>627.00</td>\n",
       "      <td>100812365</td>\n",
       "      <td>100812869</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.03</td>\n",
       "      <td>1.03</td>\n",
       "      <td>9.96</td>\n",
       "      <td>42.15</td>\n",
       "      <td>71.37</td>\n",
       "      <td>-1967.03</td>\n",
       "      <td>-2345.67</td>\n",
       "      <td>-20.98</td>\n",
       "      <td>1.41</td>\n",
       "      <td>2.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594889</th>\n",
       "      <td>18</td>\n",
       "      <td>13</td>\n",
       "      <td>male</td>\n",
       "      <td>3</td>\n",
       "      <td>540</td>\n",
       "      <td>2682.00</td>\n",
       "      <td>2682.00</td>\n",
       "      <td>362862440</td>\n",
       "      <td>362881912</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-29.22</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-371.25</td>\n",
       "      <td>-554.29</td>\n",
       "      <td>-20.98</td>\n",
       "      <td>-0.97</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100379</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>unknown</td>\n",
       "      <td>7</td>\n",
       "      <td>547</td>\n",
       "      <td>2384.00</td>\n",
       "      <td>2682.00</td>\n",
       "      <td>382888820</td>\n",
       "      <td>383039868</td>\n",
       "      <td>214.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.90</td>\n",
       "      <td>21.64</td>\n",
       "      <td>34.18</td>\n",
       "      <td>-2480.05</td>\n",
       "      <td>344.36</td>\n",
       "      <td>9.19</td>\n",
       "      <td>0.73</td>\n",
       "      <td>1.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207602</th>\n",
       "      <td>35</td>\n",
       "      <td>13</td>\n",
       "      <td>female</td>\n",
       "      <td>7</td>\n",
       "      <td>720</td>\n",
       "      <td>2529.00</td>\n",
       "      <td>2956.00</td>\n",
       "      <td>483713706</td>\n",
       "      <td>483807163</td>\n",
       "      <td>341.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>44.20</td>\n",
       "      <td>19.09</td>\n",
       "      <td>-1495.13</td>\n",
       "      <td>-544.06</td>\n",
       "      <td>38.55</td>\n",
       "      <td>1.47</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 164 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        bd city   gender registered_via  SUM(transactions.payment_plan_days)  \\\n",
       "551174  28    5     male              3                                  180   \n",
       "403333  20   13     male              3                                  127   \n",
       "594889  18   13     male              3                                  540   \n",
       "100379   0    1  unknown              7                                  547   \n",
       "207602  35   13   female              7                                  720   \n",
       "\n",
       "        SUM(transactions.plan_list_price)  \\\n",
       "551174                             298.00   \n",
       "403333                             627.00   \n",
       "594889                            2682.00   \n",
       "100379                            2384.00   \n",
       "207602                            2529.00   \n",
       "\n",
       "        SUM(transactions.actual_amount_paid)  \\\n",
       "551174                                894.00   \n",
       "403333                                627.00   \n",
       "594889                               2682.00   \n",
       "100379                               2682.00   \n",
       "207602                               2956.00   \n",
       "\n",
       "        SUM(transactions.transaction_date)  \\\n",
       "551174                           120923653   \n",
       "403333                           100812365   \n",
       "594889                           362862440   \n",
       "100379                           382888820   \n",
       "207602                           483713706   \n",
       "\n",
       "        SUM(transactions.membership_expire_date)  \\\n",
       "551174                                 120924153   \n",
       "403333                                 100812869   \n",
       "594889                                 362881912   \n",
       "100379                                 383039868   \n",
       "207602                                 483807163   \n",
       "\n",
       "        SUM(transactions.price_difference)  ...  \\\n",
       "551174                              428.00  ...   \n",
       "403333                                0.00  ...   \n",
       "594889                                0.00  ...   \n",
       "100379                              214.00  ...   \n",
       "207602                              341.00  ...   \n",
       "\n",
       "        DIFF(MAX(transactions.planned_daily_price))  \\\n",
       "551174                                         1.67   \n",
       "403333                                         1.03   \n",
       "594889                                         0.00   \n",
       "100379                                         0.00   \n",
       "207602                                         0.00   \n",
       "\n",
       "        DIFF(MAX(transactions.daily_price))  \\\n",
       "551174                                 1.67   \n",
       "403333                                 1.03   \n",
       "594889                                 0.00   \n",
       "100379                                 0.00   \n",
       "207602                                 0.00   \n",
       "\n",
       "        DIFF(STD(transactions.payment_plan_days))  \\\n",
       "551174                                       0.00   \n",
       "403333                                       9.96   \n",
       "594889                                       0.00   \n",
       "100379                                       4.90   \n",
       "207602                                       0.00   \n",
       "\n",
       "        DIFF(STD(transactions.plan_list_price))  \\\n",
       "551174                                    76.94   \n",
       "403333                                    42.15   \n",
       "594889                                   -29.22   \n",
       "100379                                    21.64   \n",
       "207602                                    44.20   \n",
       "\n",
       "        DIFF(STD(transactions.actual_amount_paid))  \\\n",
       "551174                                        0.00   \n",
       "403333                                       71.37   \n",
       "594889                                        0.00   \n",
       "100379                                       34.18   \n",
       "207602                                       19.09   \n",
       "\n",
       "        DIFF(STD(transactions.transaction_date))  \\\n",
       "551174                                   3890.64   \n",
       "403333                                  -1967.03   \n",
       "594889                                   -371.25   \n",
       "100379                                  -2480.05   \n",
       "207602                                  -1495.13   \n",
       "\n",
       "        DIFF(STD(transactions.membership_expire_date))  \\\n",
       "551174                                         3353.08   \n",
       "403333                                        -2345.67   \n",
       "594889                                         -554.29   \n",
       "100379                                          344.36   \n",
       "207602                                         -544.06   \n",
       "\n",
       "        DIFF(STD(transactions.price_difference))  \\\n",
       "551174                                     55.25   \n",
       "403333                                    -20.98   \n",
       "594889                                    -20.98   \n",
       "100379                                      9.19   \n",
       "207602                                     38.55   \n",
       "\n",
       "        DIFF(STD(transactions.planned_daily_price))  \\\n",
       "551174                                         2.56   \n",
       "403333                                         1.41   \n",
       "594889                                        -0.97   \n",
       "100379                                         0.73   \n",
       "207602                                         1.47   \n",
       "\n",
       "        DIFF(STD(transactions.daily_price))  \n",
       "551174                                 0.00  \n",
       "403333                                 2.33  \n",
       "594889                                 0.00  \n",
       "100379                                 1.08  \n",
       "207602                                 0.64  \n",
       "\n",
       "[5 rows x 164 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the pre-split data\n",
    "\n",
    "store = pd.HDFStore('/home/dissertation/data/dfs_abt_split.h5')\n",
    "X_train, X_test, y_train, y_test = store['X_train'], store['X_test'], store['y_train'], store['y_test']\n",
    "store.close()\n",
    "\n",
    "# Drop msno from the dataset\n",
    "X_train.drop(['msno', 'registration_init_time', 'registration_init_time_dt'], inplace=True, axis=1, errors='ignore')\n",
    "X_test.drop(['msno', 'registration_init_time', 'registration_init_time_dt'], inplace=True, axis=1, errors='ignore')\n",
    "\n",
    "print(\"Train Shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Train Shape:\", X_test.shape, y_test.shape)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42 \n",
    "CV_ITER = None\n",
    "SCORING_METRIC = autosklearn.metrics.recall\n",
    "BASE_NAME = \"askbasic_\" + str(CV_ITER) + \"cv_\" + str(SCORING_METRIC)\n",
    "N_JOBS = 2\n",
    "## Time periods to train for in minutes\n",
    "# TIME_PERIODS = [0.25, 0.5, 1, 2, 3, 4]\n",
    "TIME_PERIODS = [10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60]\n",
    "\n",
    "## Set the list of the categorical columns in the dataset\n",
    "cat_col= ['gender', 'city', 'registered_via']\n",
    "\n",
    "df_cols = X_train.columns\n",
    "feat_types =  ['Categorical' if col in cat_col else 'Numerical' for col in df_cols]\n",
    "\n",
    "classifiers = []\n",
    "\n",
    "## Each entry in the list is a Tuple of\n",
    "##   [ModelName, Model, HyperParams, ScoringMetric]    \n",
    "for period in TIME_PERIODS:\n",
    "    classifiers.append(\n",
    "        ('ASKLEARN_{}_'.format(str(period)) + BASE_NAME,                        ## ModelName\n",
    "         autosklearn.classification.AutoSklearnClassifier(                      ## Model  \n",
    "                time_left_for_this_task=int(60*period), \n",
    "                n_jobs=N_JOBS,\n",
    "                include_estimators=[\"random_forest\", \"decision_tree\", \"adaboost\", \"gaussian_nb\",\n",
    "                                    \"liblinear_svc\", \"xgradient_boosting\"], \n",
    "                exclude_estimators=None,\n",
    "                include_preprocessors=[\"no_preprocessing\", ], \n",
    "                exclude_preprocessors=None,\n",
    "                ml_memory_limit = 3072*9), \n",
    "         {},                                                                    ## HyperParams\n",
    "         SCORING_METRIC)                                                        ## ScoringMetric \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics = pd.DataFrame()\n",
    "all_results = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('/tmp/dfsask_all_metrics.pickle', 'rb') as f:\n",
    "#     # The protocol version used is detected automatically, so we do not\n",
    "#     # have to specify it.\n",
    "#     all_metrics = pickle.load(f)\n",
    "\n",
    "# with open('/tmp/dfsask_all_results.pickle', 'rb') as f:\n",
    "#     # The protocol version used is detected automatically, so we do not\n",
    "#     # have to specify it.\n",
    "#     all_results = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Write (overwrite) the file to store the experiment results\n",
    "# with open('/tmp/dfsask_all_metrics.pickle', 'wb') as f:\n",
    "#     # Pickle the 'data' dictionary using the highest protocol available.\n",
    "#     print(\"Writing results to\", f.name)\n",
    "#     pickle.dump(all_metrics, f, pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "# # Write (overwrite) the file to store the experiment results\n",
    "# with open('/tmp/dfsask_all_results.pickle', 'wb') as f:\n",
    "#     # Pickle the 'data' dictionary using the highest protocol available.\n",
    "#     print(\"Writing results to\", f.name)\n",
    "#     pickle.dump(all_results, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1.1 Baseline - Default Settings - No sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "start = time.time()\n",
    "\n",
    "sampler = ('None', DummySampler())\n",
    "\n",
    "exp_metrics, model_results = perform_experiment(X_train, X_test, y_train, y_test, classifiers, sampler, 1, \\\n",
    "                                                cv_iter=CV_ITER, cat_col=cat_col, auto_ml = False)\n",
    "\n",
    "all_metrics = all_metrics.append(exp_metrics)\n",
    "all_results.append((sampler[0]+\"_\"+BASE_NAME, exp_metrics, model_results))\n",
    "\n",
    "log(\"basic, autosklearn, {0}, {1}\".format(sampler[0], time.time()-start), 'Basic_Autosklearn.log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sampling_method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RUS 1:1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ROS 3:1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ROS 2:1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ROS 1:1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ROS 3:2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sampling_method\n",
       "0         RUS 1:1\n",
       "0            None\n",
       "0         ROS 3:1\n",
       "0         ROS 2:1\n",
       "0         ROS 1:1\n",
       "0         ROS 3:2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_metrics[['sampling_method']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics[['label','sampling_method']].groupby(['sampling_method']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics.groupby('sampling_method').train_time.sum()/60/60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1.2 Baseline - Default Settings - Oversampled training set 100%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "start = time.time()\n",
    "\n",
    "sampler = ('ROS 1:1', RandomOverSampler(random_state=RANDOM_STATE))\n",
    "\n",
    "exp_metrics, model_results = perform_experiment(X_train, X_test, y_train, y_test, classifiers, sampler, 1, \\\n",
    "                                                cv_iter=CV_ITER, cat_col=cat_col, auto_ml = False)\n",
    "\n",
    "all_metrics = all_metrics.append(exp_metrics)\n",
    "all_results.append((sampler[0]+\"_\"+BASE_NAME, exp_metrics, model_results))\n",
    "\n",
    "log(\"basic, autosklearn, {0}, {1}\".format(sampler[0], time.time()-start), 'Basic_Autosklearn.log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1.3 Baseline - Default Settings - Undersampled training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "start = time.time()\n",
    "\n",
    "sampler = ('RUS 1:1', RandomUnderSampler(random_state=RANDOM_STATE))\n",
    "\n",
    "exp_metrics, model_results = perform_experiment(X_train, X_test, y_train, y_test, classifiers, sampler, 1, \\\n",
    "                                                cv_iter=CV_ITER, cat_col=cat_col, auto_ml = False)\n",
    "\n",
    "all_metrics = all_metrics.append(exp_metrics)\n",
    "all_results.append((sampler[0]+\"_\"+BASE_NAME, exp_metrics, model_results))\n",
    "\n",
    "log(\"basic, autosklearn, {0}, {1}\".format(sampler[0], time.time()-start), 'Basic_Autosklearn.log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sys.getsizeof(model)\n",
    "# model = all_results[0][2][0][-1]\n",
    "# print(model.sprint_statistics())\n",
    "# print(model.show_models())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1.4 Baseline - Default Settings - Over sampling - 33% of majority size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "start = time.time()\n",
    "\n",
    "sampler = ('ROS 3:1', RandomOverSampler(random_state=RANDOM_STATE, sampling_strategy = 1/3))\n",
    "\n",
    "exp_metrics, model_results = perform_experiment(X_train, X_test, y_train, y_test, classifiers, sampler, 1, \\\n",
    "                                                cv_iter=CV_ITER, cat_col=cat_col, auto_ml = False)\n",
    "\n",
    "all_metrics = all_metrics.append(exp_metrics)\n",
    "all_results.append((sampler[0]+\"_\"+BASE_NAME, exp_metrics, model_results))\n",
    "\n",
    "log(\"basic, autosklearn, {0}, {1}\".format(sampler[0], time.time()-start), 'Basic_Autosklearn.log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics.sampling_method.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics.sort_values(['balanced_accuracy', 'recall'], ascending=[False, False]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1.5 Baseline - Default Settings - Over sampling - 66% of majority size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "start = time.time()\n",
    "\n",
    "sampler = ('ROS 3:2', RandomOverSampler(random_state=RANDOM_STATE, sampling_strategy = 2/3))\n",
    "\n",
    "exp_metrics, model_results = perform_experiment(X_train, X_test, y_train, y_test, classifiers, sampler, 1, \\\n",
    "                                                cv_iter=CV_ITER, cat_col=cat_col, auto_ml = False)\n",
    "\n",
    "all_metrics = all_metrics.append(exp_metrics)\n",
    "all_results.append((sampler[0]+\"_\"+BASE_NAME, exp_metrics, model_results))\n",
    "\n",
    "log(\"basic, autosklearn, {0}, {1}\".format(sampler[0], time.time()-start), 'Basic_Autosklearn.log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1.6 Baseline - Default Settings - Over sampling - 50% of majority size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "start = time.time()\n",
    "\n",
    "sampler = ('ROS 2:1', RandomOverSampler(random_state=RANDOM_STATE, sampling_strategy = 1/2))\n",
    "\n",
    "exp_metrics, model_results = perform_experiment(X_train, X_test, y_train, y_test, classifiers, sampler, 1, \\\n",
    "                                                cv_iter=CV_ITER, cat_col=cat_col, auto_ml = False)\n",
    "\n",
    "all_metrics = all_metrics.append(exp_metrics)\n",
    "all_results.append((sampler[0]+\"_\"+BASE_NAME, exp_metrics, model_results))\n",
    "\n",
    "log(\"basic, autosklearn, {0}, {1}\".format(sampler[0], time.time()-start), 'Basic_Autosklearn.log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1.7 Baseline Default Settings SMOTE-NC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRE-SAMPLING: (600803, 164) (600803,) Counter({0: 544661, 1: 56142})\n"
     ]
    }
   ],
   "source": [
    "sampler = ('SMOTE_NC', SMOTENC(random_state=RANDOM_STATE, categorical_features=[0,1,2,3,4,5,6,7,8,13,14], n_jobs=8))\n",
    "\n",
    "X_train_t, X_test_t, y_train_t, y_test_t = \\\n",
    "    prepare_train_test_data(X_train, X_test, y_train, y_test, \n",
    "                            sampler = RandomOverSampler(random_state=RANDOM_STATE), \n",
    "                            cat_col = cat_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "start = time.time()\n",
    "sampler = ('SMOTE_NC', DummySampler())\n",
    "\n",
    "## Keep the following, essentially dropping the dt columns\n",
    "cols = ['is_churn', 'city', 'bd', 'registered_via', 'total_order',\n",
    "       'payment_method_id_mode', 'payment_method_id_count',\n",
    "       'payment_plan_days_mode', 'payment_plan_days_mean',\n",
    "       'plan_list_price_mean', 'plan_lifetime_value', 'actual_amount_mean',\n",
    "       'total_actual_amount', 'is_auto_renew_mode', 'cancel_times']\n",
    "\n",
    "exp_metrics, model_results = perform_experiment(X_train_t, X_test_t, y_train_t, y_test_t, classifiers, sampler, 1, \\\n",
    "                                                cv_iter=CV_ITER, cat_col=[], auto_ml = False, \n",
    "                                                n_jobs = 4, prepare_data = False)\n",
    "\n",
    "all_metrics = all_metrics.append(exp_metrics)\n",
    "all_results.append((sampler[0]+\"_\"+BASE_NAME, exp_metrics, model_results))\n",
    "\n",
    "log(\"basic, autosklearn, {0}, {1}\".format(sampler[0], time.time()-start), 'Basic_Autosklearn.log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics.sort_values('recall', ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#store(all_results, 'Asklearn_Default_Undersample.pickle')\n",
    "\n",
    "# Write (overwrite) the file to store the experiment results\n",
    "with open('Manual_Asklearn_20190813.pickle', 'wb') as f:\n",
    "    # Pickle the 'data' dictionary using the highest protocol available.\n",
    "    print(\"Writing results to\", f.name)\n",
    "    pickle.dump(all_results, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Just try an SVM \n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model_train_results = train_model(base_dataset, sampling_method = 'under', classifiers = [('SGDClassifier', SGDClassifier(loss='log'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Print the feature importance \n",
    "\n",
    "feature_index = np.flip(np.argsort(model.feature_importances_), axis=0)\n",
    "ordered_features = []\n",
    "column_names = X_test.columns\n",
    "\n",
    "for i in feature_index[0:10]:\n",
    "    print(np.round(model.feature_importances_[i], 3), ' --> ', column_names[i])\n",
    "    ordered_features.append(column_names[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Print the permutation importance \n",
    "\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "\n",
    "_, X_test, _, y_test = prepare_train_test_split(model_dataset, 0)\n",
    "\n",
    "perm = PermutationImportance(model, random_state=1).fit(X_test, y_test)\n",
    "\n",
    "eli5.show_weights(perm, feature_names = X_test.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_name, model = model_train_results[1][2]\n",
    "\n",
    "for model_name, model in model_train_results[1]:\n",
    "    probs = model.predict_proba(X_test)[:, 1]\n",
    "    pr_data = plot_precision_recall(\n",
    "        y_test, probs, title='PR Curve for {0}'.format(model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = model.predict_proba(X_test)[:, 1]\n",
    "pr_data = plot_precision_recall(\n",
    "    y_test, probs, title='PR Curve for {0}'.format(model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_data = plot_roc(\n",
    "    y_test, probs, title='ROC Curve for {0}'.format(model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(plt.style.available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Original Data distribution\")\n",
    "print(model_dataset['is_churn'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display new class counts\n",
    "print('Sci-Kit Learn : resample : Down Sampled data set')\n",
    "train_downsample = undersampled_dataset(model_dataset, 'is_churn')\n",
    "\n",
    "print(train_downsample['is_churn'].value_counts())\n",
    "print(\"Num records = \", train_downsample.shape[0])\n",
    "train_downsample.is_churn.value_counts().plot(kind='bar', title='Count (target)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display new class counts\n",
    "print('Sci-Kit Learn : resample : Up Sampled data set')\n",
    "train_upsample = oversampled_dataset(model_dataset, 'is_churn')\n",
    "\n",
    "print(train_upsample['is_churn'].value_counts())\n",
    "print(\"Num records = \", train_upsample.shape[0])\n",
    "train_upsample.is_churn.value_counts().plot(kind='bar', title='Count (target)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "probs = model.predict_proba(X_test)[:, 1]\n",
    "pr_data = plot_precision_recall(\n",
    "    y_test, probs, title='Precision-Recall Curve for Random Forest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_above = pr_data.loc[pr_data['precision'] >= 0.25].copy()\n",
    "precision_above.sort_values('recall', ascending=False, inplace=True)\n",
    "precision_above.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "threshold_required = 0.5\n",
    "# Make predictions where probability is above threshold\n",
    "preds = np.zeros(len(y_test))\n",
    "preds[probs >= threshold_required] = 1\n",
    "\n",
    "# Make and plot confusion matrix\n",
    "cm = confusion_matrix(y_test, preds)\n",
    "plot_confusion_matrix(cm, classes=['No Churn', 'Churn'],\n",
    "                      title='Churn Confusion Matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi = pd.DataFrame({'importance': model.feature_importances_}, index=model_dataset.iloc[:, 1:].columns).\\\n",
    "    sort_values('importance', ascending=False)\n",
    "fi.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
