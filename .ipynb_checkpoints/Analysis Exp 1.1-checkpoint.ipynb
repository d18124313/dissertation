{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anaconda/envs/py373/lib/python3.7/site-packages/pyparsing.py:2927: FutureWarning: Possible set intersection at position 3\n",
      "  self.re = re.compile( self.reString )\n",
      "/home/anaconda/envs/py373/lib/python3.7/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import gc; gc.enable()\n",
    "import time\n",
    "import sys\n",
    "\n",
    "pd.options.display.float_format = \"{:.3f}\".format\n",
    "np.set_printoptions(precision=4)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "sys.path.append('modules')\n",
    "\n",
    "from shared_functions import *\n",
    "\n",
    "import pickle\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.core.interactiveshell import InteractiveShell\n",
    "# InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_results(file_name):\n",
    "    data = None\n",
    "    with open(file_name, 'rb') as f:\n",
    "        # The protocol version used is detected automatically, so we do not\n",
    "        # have to specify it.\n",
    "        data = pickle.load(f)\n",
    "    return data\n",
    "\n",
    "def filter_top_model_results(top_models, all_model_results):\n",
    "    plot_data = list()\n",
    "    for idx, row in top_models.iterrows():\n",
    "        #print(\"row.label: \" + row.label + ',' + row.classifier + ',' + row.sampling_method)\n",
    "        for res in all_model_results:       \n",
    "            for alg_results in res:\n",
    "                if alg_results[0] == row.label and alg_results[1] == row.classifier and alg_results[2] == row.sampling_method:\n",
    "                    #print(alg_results)\n",
    "                    label, model_name, sampling_method, _, tpr, fpr, roc_auc, precision, recall, prc_auc = alg_results\n",
    "\n",
    "                    plot_data.append((\"{} :: {}\".format(model_name, sampling_method), tpr, fpr, roc_auc, precision, recall, prc_auc))\n",
    "    return plot_data\n",
    "\n",
    "def rebuild_results(res):\n",
    "    ## Gather all the metrics\n",
    "    temp_metrics = pd.DataFrame()\n",
    "    temp_results = list()\n",
    "    for i in range(0, len(res)):\n",
    "        temp_metrics = pd.concat([temp_metrics, res[i][1]])\n",
    "        temp_results.append(res[i][2]) \n",
    "    \n",
    "    return temp_metrics, temp_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "measurements = ['classifier', 'sampling_method', \\\n",
    "                #'fp', 'fn',\\\n",
    "                'balanced_accuracy', 'recall', 'precision', \\\n",
    "                 #'f1_score',\\\n",
    "                'train_time', 'aucroc', 'auprc',\\\n",
    "                'model_churn_cost']\n",
    "\n",
    "measurements_alias = ['classifier', 'sampling', \\\n",
    "                      'bal_acc', 'recall', 'precision',\\\n",
    "                      # 'f1',\\\n",
    "                      'train_time', 'auroc', 'auprc',\\\n",
    "                      'churn_cost']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarise performance of the approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## First Experiment:\n",
    "## Approach 1.1 - Churn BasicData + Default Hyper\n",
    "\n",
    "#exp1_1 = load_results('/home/dissertation/code/RESULTS_FINAL/Basic_DefaultHyper_2019-08-12.pickle')\n",
    "\n",
    "#exp2_1 = load_results('/home/dissertation/code/RESULTS_FINAL/Manual_GridSearch_2019-08-10.pickle')\n",
    "\n",
    "exp2_2 = load_results('/home/dissertation/code/RESULTS_FINAL/Manual_RdmSearch_2019-08-10.pickle')\n",
    "\n",
    "#exp3_1 = load_results('/home/dissertation/code/RESULTS_FINAL/DFS_Default_2019-08-10.pickle')\n",
    "\n",
    "#exp4_1 = load_results('/home/dissertation/code/RESULTS_FINAL/Basic_Asklearn_20190813.pickle')\n",
    "                      \n",
    "exp_metrics, exp_results = rebuild_results(exp2_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exp_metrics[['classifier', 'sampling_method','accuracy']].groupby(['sampling_method']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>classifier</th>\n",
       "      <th>sampling_method</th>\n",
       "      <th>tn</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "      <th>fp</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>...</th>\n",
       "      <th>log_loss</th>\n",
       "      <th>train_time</th>\n",
       "      <th>cv_time</th>\n",
       "      <th>aucroc</th>\n",
       "      <th>auprc</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>cv_score_mean</th>\n",
       "      <th>cv_score_std</th>\n",
       "      <th>model_churn_cost</th>\n",
       "      <th>sample</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NB_random_5cv_recall</td>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>None</td>\n",
       "      <td>201877</td>\n",
       "      <td>10359</td>\n",
       "      <td>13702</td>\n",
       "      <td>31549</td>\n",
       "      <td>0.837</td>\n",
       "      <td>0.303</td>\n",
       "      <td>0.569</td>\n",
       "      <td>...</td>\n",
       "      <td>5.622</td>\n",
       "      <td>3.645</td>\n",
       "      <td>2.641</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.412</td>\n",
       "      <td>0.717</td>\n",
       "      <td>0.570</td>\n",
       "      <td>0.003</td>\n",
       "      <td>9704600</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DT_random_5cv_recall</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>None</td>\n",
       "      <td>191512</td>\n",
       "      <td>5517</td>\n",
       "      <td>18544</td>\n",
       "      <td>41914</td>\n",
       "      <td>0.816</td>\n",
       "      <td>0.307</td>\n",
       "      <td>0.771</td>\n",
       "      <td>...</td>\n",
       "      <td>6.362</td>\n",
       "      <td>2002.497</td>\n",
       "      <td>39.054</td>\n",
       "      <td>0.864</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.796</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.006</td>\n",
       "      <td>8804300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RF_random_5cv_recall</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>None</td>\n",
       "      <td>200034</td>\n",
       "      <td>5976</td>\n",
       "      <td>18085</td>\n",
       "      <td>33392</td>\n",
       "      <td>0.847</td>\n",
       "      <td>0.351</td>\n",
       "      <td>0.752</td>\n",
       "      <td>...</td>\n",
       "      <td>5.281</td>\n",
       "      <td>1665.059</td>\n",
       "      <td>32.691</td>\n",
       "      <td>0.881</td>\n",
       "      <td>0.578</td>\n",
       "      <td>0.804</td>\n",
       "      <td>0.744</td>\n",
       "      <td>0.005</td>\n",
       "      <td>8135700</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR_random_5cv_recall</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>None</td>\n",
       "      <td>134226</td>\n",
       "      <td>8164</td>\n",
       "      <td>15897</td>\n",
       "      <td>99200</td>\n",
       "      <td>0.583</td>\n",
       "      <td>0.138</td>\n",
       "      <td>0.661</td>\n",
       "      <td>...</td>\n",
       "      <td>14.402</td>\n",
       "      <td>178.124</td>\n",
       "      <td>2.520</td>\n",
       "      <td>0.683</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.618</td>\n",
       "      <td>0.650</td>\n",
       "      <td>0.004</td>\n",
       "      <td>15591700</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLP_random_5cv_recall</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>None</td>\n",
       "      <td>231843</td>\n",
       "      <td>18226</td>\n",
       "      <td>5835</td>\n",
       "      <td>1583</td>\n",
       "      <td>0.923</td>\n",
       "      <td>0.787</td>\n",
       "      <td>0.243</td>\n",
       "      <td>...</td>\n",
       "      <td>2.657</td>\n",
       "      <td>2998.235</td>\n",
       "      <td>377.757</td>\n",
       "      <td>0.838</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.618</td>\n",
       "      <td>0.294</td>\n",
       "      <td>0.088</td>\n",
       "      <td>9854800</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   label              classifier sampling_method      tn  \\\n",
       "0   NB_random_5cv_recall              GaussianNB            None  201877   \n",
       "0   DT_random_5cv_recall  DecisionTreeClassifier            None  191512   \n",
       "0   RF_random_5cv_recall  RandomForestClassifier            None  200034   \n",
       "0   LR_random_5cv_recall      LogisticRegression            None  134226   \n",
       "0  MLP_random_5cv_recall           MLPClassifier            None  231843   \n",
       "\n",
       "      fn     tp     fp  accuracy  precision  recall  ...  log_loss  \\\n",
       "0  10359  13702  31549     0.837      0.303   0.569  ...     5.622   \n",
       "0   5517  18544  41914     0.816      0.307   0.771  ...     6.362   \n",
       "0   5976  18085  33392     0.847      0.351   0.752  ...     5.281   \n",
       "0   8164  15897  99200     0.583      0.138   0.661  ...    14.402   \n",
       "0  18226   5835   1583     0.923      0.787   0.243  ...     2.657   \n",
       "\n",
       "   train_time  cv_time  aucroc  auprc  balanced_accuracy  cv_score_mean  \\\n",
       "0       3.645    2.641   0.765  0.412              0.717          0.570   \n",
       "0    2002.497   39.054   0.864  0.593              0.796          0.765   \n",
       "0    1665.059   32.691   0.881  0.578              0.804          0.744   \n",
       "0     178.124    2.520   0.683  0.320              0.618          0.650   \n",
       "0    2998.235  377.757   0.838  0.510              0.618          0.294   \n",
       "\n",
       "   cv_score_std  model_churn_cost  sample  \n",
       "0         0.003           9704600       0  \n",
       "0         0.006           8804300       0  \n",
       "0         0.005           8135700       0  \n",
       "0         0.004          15591700       0  \n",
       "0         0.088           9854800       0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_metrics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert train_time\n",
    "exp_metrics['train_time'] = (exp_metrics['train_time']/60)\n",
    "exp_metrics['cv_time'] = (exp_metrics['cv_time']/60)\n",
    "\n",
    "# Convert model_churn_cost to EUR from TWD\n",
    "exp_metrics['model_churn_cost'] = np.round(exp_metrics['model_churn_cost'] * 0.029).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "measure_by = ['balanced_accuracy', 'recall', 'model_churn_cost']\n",
    "measure_by_sort = [False, False, True]\n",
    "\n",
    "# measure_by = ['balanced_accuracy']\n",
    "# measure_by_sort = [False]\n",
    "\n",
    "# measure_by = ['model_churn_cost']\n",
    "# measure_by_sort = [True]\n",
    "\n",
    "# measure_by = ['f1_score']\n",
    "# measure_by_sort = [False]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The best/worst 5 performing models as measured by .... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting best results for ['balanced_accuracy', 'recall', 'model_churn_cost'] / ordered ascending? [False, False, True]\n",
      "Getting worst results for ['balanced_accuracy', 'recall', 'model_churn_cost'] / ordered ascending? [True, True, False]\n",
      "\\begin{tabular}{llrrrrrrr}\n",
      "\\toprule\n",
      "         classifier & sampling &  bal\\_acc &  recall &  precision &  train\\_time &  auroc &  auprc &  churn\\_cost \\\\\n",
      "\\midrule\n",
      "       RandomForest &  ROS 2:1 &    0.809 &   0.764 &      0.351 &      40.997 &  0.886 &  0.600 &      234120 \\\\\n",
      "       RandomForest &  ROS 1:1 &    0.809 &   0.757 &      0.361 &      64.087 &  0.887 &  0.603 &      231295 \\\\\n",
      "       RandomForest &  ROS 3:1 &    0.808 &   0.749 &      0.369 &      32.605 &  0.887 &  0.601 &      229219 \\\\\n",
      "       RandomForest &  ROS 3:2 &    0.808 &   0.758 &      0.354 &      51.502 &  0.885 &  0.594 &      233595 \\\\\n",
      "       RandomForest &  RUS 1:1 &    0.805 &   0.768 &      0.334 &       2.940 &  0.880 &  0.573 &      241619 \\\\\n",
      "                XGB &     None &    0.606 &   0.216 &      0.834 &      17.802 &  0.838 &  0.519 &      291467 \\\\\n",
      " LogisticRegression &  ROS 1:1 &    0.608 &   0.689 &      0.131 &       7.893 &  0.688 &  0.337 &      476395 \\\\\n",
      " LogisticRegression &     None &    0.618 &   0.661 &      0.138 &       2.969 &  0.683 &  0.320 &      452159 \\\\\n",
      "                MLP &     None &    0.618 &   0.243 &      0.787 &      49.971 &  0.838 &  0.510 &      285789 \\\\\n",
      "                MLP &  ROS 3:1 &    0.694 &   0.420 &      0.569 &      85.261 &  0.848 &  0.511 &      253834 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Getting best results for {} / ordered ascending? {}\".format(measure_by, measure_by_sort))\n",
    "\n",
    "top_results = exp_metrics.sort_values(measure_by, ascending=measure_by_sort)\n",
    "top_results = top_results[measurements].head(5)\n",
    "top_results['classifier'] = top_results['classifier'].apply(lambda v: str(v).replace('Classifier', ''))\n",
    "\n",
    "### The lowest 5 performing models by approach as measured by .... \n",
    "print(\"Getting worst results for {} / ordered ascending? {}\".format(measure_by, [not f for f in measure_by_sort]))\n",
    "worst_results = exp_metrics\\\n",
    "                .sort_values(measure_by, ascending=[not f for f in measure_by_sort])\n",
    "worst_results = worst_results[measurements].head(5)\n",
    "worst_results['classifier'] = worst_results['classifier'].apply(lambda v: str(v).replace('Classifier', ''))\n",
    "\n",
    "temp = pd.concat([top_results, worst_results])\n",
    "temp.columns = measurements_alias\n",
    "temp\n",
    "\n",
    "print(temp.to_latex(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp_metrics[['label','classifier','sampling_method','accuracy','precision','recall','tp','tn','fp','fn']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary performance statistics of classifiers over all sampling techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Excludes LR and MLP as those produce bad classifiers\n",
    "\n",
    "stats_summary = {'best':max,\n",
    "                 'median':'median', \n",
    "                 'iqr':lambda x: np.percentile(x, 75, interpolation='higher') - np.percentile(x, 25, interpolation='lower'),\n",
    "                 #'range':lambda x: max(x) - min(x)\n",
    "                }\n",
    "#[~exp_metrics.recall.isin([0.0, 1.0])]\n",
    "summary = \\\n",
    "    exp_metrics\\\n",
    "            .groupby(['classifier'])\\\n",
    "            .agg({\n",
    "                 'balanced_accuracy':stats_summary,\n",
    "                 'recall':stats_summary,\n",
    "                 'precision':stats_summary,\n",
    "                 'model_churn_cost':{'best':min},\n",
    "                 #'aucroc':stats_summary,\n",
    "                 #'auprc':stats_summary,\n",
    "                 'train_time':'median',\n",
    "                 })\\\n",
    "            .reset_index()\\\n",
    "            .sort_values(('balanced_accuracy', 'best'), ascending=False)\n",
    "summary\n",
    "#print(summary.to_latex(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The best performing sampling methods by classifier as measured by .... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Getting results for {} / ordered ascending? {}\".format(measure_by, measure_by_sort))\n",
    "\n",
    "top_results = exp_metrics.sort_values(measure_by, ascending=measure_by_sort).groupby('classifier').head(1)\n",
    "top_results = top_results[measurements]\n",
    "top_results['classifier'] = top_results['classifier'].apply(lambda v: str(v).replace('Classifier', ''))\n",
    "top_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The best performing models by sampling method as measured by .... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Getting results for {} / ordered ascending? {}\".format(measure_by, measure_by_sort))\n",
    "top_results = exp_metrics[(exp_metrics.recall > 0) & (exp_metrics.recall < 1)]\\\n",
    "                    .sort_values(measure_by, ascending=measure_by_sort).groupby('sampling_method').head(1)\n",
    "top_results = top_results[measurements]\n",
    "top_results.sort_values('balanced_accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier train time distribution by sampling method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "plt.ylabel('Seconds')\n",
    "exp_metrics.boxplot(column='train_time', by='sampling_method', ax=ax)\n",
    "plt.title('Classifier Training Time Distribution\\n', size=17)\n",
    "plt.suptitle(' ')\n",
    "plt.xlabel('Sampling Method')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For this approach plot the best models by classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"Getting best results by classifier based on {} / ordered ascending? {}\".format(measure_by, measure_by_sort))\n",
    "plot_results = exp_metrics.sort_values(measure_by, ascending=measure_by_sort).groupby('classifier').head(1)\n",
    "plot_data = filter_top_model_results(plot_results, exp_results)\n",
    "plot_roc_prc(plot_data, ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing the best model and appending to overall .... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp1_1 = load_results('/home/dissertation/code/RESULTS_FINAL/Basic_DefaultHyper_2019-08-12.pickle')\n",
    "exp_metrics, exp_results = rebuild_results(exp1_1)\n",
    "manualgrid = load_results('Manual_GridSearch_2019-08-05.pickle')\n",
    "\n",
    "manualrdm = load_results('Manual_RdmSearch_2019-08-05.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_models = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_models = top_models.append(exp_metrics.sort_values(measure_by, ascending=measure_by_sort).head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter_top_model_results(exp_metrics.sort_values(measure_by, ascending=measure_by_sort).head(1), exp_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import scikit_posthocs as sp\n",
    "\n",
    "xgb = plot_data[0][-2]\n",
    "rf = plot_data[1][-2]\n",
    "dt = plot_data[2][-2]\n",
    "gnb = plot_data[3][-2]\n",
    "lr = plot_data[4][-2]\n",
    "mlp = plot_data[5][-2]\n",
    "\n",
    "data = [xgb, rf, dt, gnb, lr, mlp]\n",
    "\n",
    "stats.kruskal(*data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp.posthoc_conover(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#all_metrics[all_metrics.recall < 1.0].sort_values(['recall'], ascending=[False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_metrics.sort_values(['recall','precision'], ascending=[False, False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(top_results.to_latex(index=False)) # doctest: +NORMALIZE_WHITESPACE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as ss\n",
    "import statsmodels.api as sa\n",
    "import scikit_posthocs as sp\n",
    "import statsmodels.formula.api as sfa\n",
    "\n",
    "df = sa.datasets.get_rdataset('iris').data\n",
    "data = [df.loc[ids, 'Sepal.Width'].values for ids in df.groupby('Species').groups.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H, p = ss.kruskal(*data)\n",
    "print(H, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp.posthoc_conover(df, val_col='Sepal.Width', group_col='Species', p_adjust = 'holm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['Sepal_Length', 'Sepal_Width', 'Petal_Length', 'Petal_Width', 'Species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = sfa.ols('Sepal_Width ~ C(Species)', data=df).fit()\n",
    "anova = sa.stats.anova_lm(lm)\n",
    "print(anova)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp.posthoc_ttest(df, val_col='Sepal_Width', group_col='Species', p_adjust='holm')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
