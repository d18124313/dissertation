{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "## @see https://www.kaggle.com/toorkp/churn-wsdm/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "init_cell": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import gc; gc.enable()\n",
    "import time\n",
    "import sys\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_curve, auc, confusion_matrix, f1_score, log_loss, confusion_matrix\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from collections import Counter\n",
    "from numpy.random import RandomState\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "pd.options.display.float_format = \"{:.2f}\".format\n",
    "np.set_printoptions(precision=4)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "sys.path.append('modules')\n",
    "\n",
    "from shared_functions import *\n",
    "\n",
    "from tpot import TPOTClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load the pre-split data\n",
    "\n",
    "store = pd.HDFStore('/home/dissertation/data/base_abt_split.h5')\n",
    "X_train, X_test, y_train, y_test = store['X_train'], store['X_test'], store['y_train'], store['y_test']\n",
    "store.close()\n",
    "\n",
    "## Set the list of the categorical columns in the dataset\n",
    "cat_col = ['city', 'registered_via', 'payment_method_id_mode']\n",
    "\n",
    "# Drop msno from the dataset\n",
    "X_train.drop(['msno', 'registration_init_time', 'registration_init_time_dt'], inplace=True, axis=1)\n",
    "X_test.drop(['msno', 'registration_init_time', 'registration_init_time_dt'], inplace=True, axis=1)\n",
    "\n",
    "print(\"Train Shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Train Shape:\", X_test.shape, y_test.shape)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42 \n",
    "CV_ITER = 2\n",
    "SCORING_METRIC = \"recall\"\n",
    "BASE_NAME = \"TPOT_\" + str(CV_ITER) + \"cv_\" + str(SCORING_METRIC)\n",
    "\n",
    "classifiers = [\n",
    "        ('TPOT_.25_' + BASE_NAME, \n",
    "         TPOTClassifier(\n",
    "                generations=100,\n",
    "                population_size=101,\n",
    "                cv=CV_ITER,\n",
    "                n_jobs=-1,\n",
    "                random_state=0,\n",
    "                verbosity=3,\n",
    "                use_dask=True,\n",
    "                scoring='recall',\n",
    "                max_time_mins = 60*.25,\n",
    "                random_state = RANDOM_STATE\n",
    "         ), {}, SCORING_METRIC),\n",
    "        ('TPOT_.5_' + BASE_NAME, \n",
    "         TPOTClassifier(\n",
    "                generations=100,\n",
    "                population_size=101,\n",
    "                cv=CV_ITER,\n",
    "                n_jobs=-1,\n",
    "                random_state=0,\n",
    "                verbosity=3,\n",
    "                use_dask=True,\n",
    "                scoring='recall',\n",
    "                max_time_mins = 60*.5,\n",
    "                random_state = RANDOM_STATE\n",
    "         ), {}, SCORING_METRIC),\n",
    "#         ('TPOT_1_' + BASE_NAME, \n",
    "#          TPOTClassifier(\n",
    "#                 generations=100,\n",
    "#                 population_size=101,\n",
    "#                 cv=CV_ITER,\n",
    "#                 n_jobs=-1,\n",
    "#                 random_state=0,\n",
    "#                 verbosity=3,\n",
    "#                 use_dask=True,\n",
    "#                 scoring='recall',\n",
    "#                 max_time_mins = 60 *1,\n",
    "#                 random_state = RANDOM_STATE\n",
    "#          ), {}, SCORING_METRIC),\n",
    "#         ('TPOT_3_' + BASE_NAME, \n",
    "#          TPOTClassifier(\n",
    "#                 generations=100,\n",
    "#                 population_size=101,\n",
    "#                 cv=CV_ITER,\n",
    "#                 n_jobs=-1,\n",
    "#                 random_state=0,\n",
    "#                 verbosity=3,\n",
    "#                 use_dask=True,\n",
    "#                 scoring='recall',\n",
    "#                 max_time_mins = 60*3,\n",
    "#                 random_state = RANDOM_STATE\n",
    "#          ), {}, SCORING_METRIC),\n",
    "#         ('TPOT_6_' + BASE_NAME, \n",
    "#          TPOTClassifier(\n",
    "#                 generations=100,\n",
    "#                 population_size=101,\n",
    "#                 cv=CV_ITER,\n",
    "#                 n_jobs=-1,\n",
    "#                 random_state=0,\n",
    "#                 verbosity=3,\n",
    "#                 use_dask=True,\n",
    "#                 scoring='recall',\n",
    "#                 max_time_mins = 60*6,\n",
    "#                 random_state = RANDOM_STATE\n",
    "#          ), {}, SCORING_METRIC),\n",
    "#         ('TPOT_12_' + BASE_NAME, \n",
    "#          TPOTClassifier(\n",
    "#                 generations=100,\n",
    "#                 population_size=101,\n",
    "#                 cv=CV_ITER,\n",
    "#                 n_jobs=-1,\n",
    "#                 random_state=0,\n",
    "#                 verbosity=3,\n",
    "#                 use_dask=True,\n",
    "#                 scoring='recall',\n",
    "#                 max_time_mins = 60*12,\n",
    "#                 random_state = RANDOM_STATE\n",
    "#          ), {}, SCORING_METRIC),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics = pd.DataFrame()\n",
    "all_results = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "client = Client(n_workers=4, threads_per_worker=1)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1.1 Baseline - Default Settings - No sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "start = time.time()\n",
    "\n",
    "sampler = ('None', DummySampler())\n",
    "\n",
    "exp_metrics, model_results = perform_experiment(X_train, X_test, y_train, y_test, classifiers, sampler, 1, \\\n",
    "                                                cv_iter=CV_ITER, cat_col=cat_col)\n",
    "\n",
    "all_metrics = all_metrics.append(exp_metrics)\n",
    "all_results.append((sampler[0]+\"_\"+BASE_NAME, exp_metrics, model_results))\n",
    "\n",
    "log(\"basic, tpot, {0}, {1}\".format(sampler[0], time.time()-start), 'Basic_Tpot.log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics.sort_values('f1_score', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1.2 Baseline - Default Settings - Oversampled training set 100%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "start = time.time()\n",
    "\n",
    "sampler = ('ROS 1:1', RandomOverSampler(random_state=RANDOM_STATE))\n",
    "\n",
    "exp_metrics, model_results = perform_experiment(X_train, X_test, y_train, y_test, classifiers, sampler, 1, \\\n",
    "                                                cv_iter=CV_ITER, cat_col=cat_col)\n",
    "\n",
    "all_metrics = all_metrics.append(exp_metrics)\n",
    "all_results.append((sampler[0]+\"_\"+BASE_NAME, exp_metrics, model_results))\n",
    "\n",
    "log(\"basic, tpot, {0}, {1}\".format(sampler[0], time.time()-start), 'Basic_Tpot.log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1.3 Baseline - Default Settings - Undersampled training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "start = time.time()\n",
    "\n",
    "sampler = ('RUS 1:1', RandomUnderSampler(random_state=RANDOM_STATE))\n",
    "\n",
    "exp_metrics, model_results = perform_experiment(X_train, X_test, y_train, y_test, classifiers, sampler, 1, \\\n",
    "                                                cv_iter=CV_ITER, cat_col=cat_col)\n",
    "\n",
    "all_metrics = all_metrics.append(exp_metrics)\n",
    "all_results.append((sampler[0]+\"_\"+BASE_NAME, exp_metrics, model_results))\n",
    "\n",
    "log(\"basic, tpot, {0}, {1}\".format(sampler[0], time.time()-start), 'Basic_Tpot.log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1.4 Baseline - Default Settings - Over sampling - 33% of majority size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "start = time.time()\n",
    "\n",
    "sampler = ('ROS 3:1', RandomOverSampler(random_state=RANDOM_STATE, sampling_strategy = 1/3))\n",
    "\n",
    "exp_metrics, model_results = perform_experiment(X_train, X_test, y_train, y_test, classifiers, sampler, 1, \\\n",
    "                                                cv_iter=CV_ITER, cat_col=cat_col)\n",
    "\n",
    "all_metrics = all_metrics.append(exp_metrics)\n",
    "all_results.append((sampler[0]+\"_\"+BASE_NAME, exp_metrics, model_results))\n",
    "\n",
    "log(\"basic, tpot, {0}, {1}\".format(sampler[0], time.time()-start), 'Basic_Tpot.log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1.5 Baseline - Default Settings - Over sampling - 66% of majority size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "start = time.time()\n",
    "\n",
    "sampler = ('ROS 3:2', RandomOverSampler(random_state=RANDOM_STATE, sampling_strategy = 2/3))\n",
    "\n",
    "exp_metrics, model_results = perform_experiment(X_train, X_test, y_train, y_test, classifiers, sampler, 1, \\\n",
    "                                                cv_iter=CV_ITER, cat_col=cat_col)\n",
    "\n",
    "all_metrics = all_metrics.append(exp_metrics)\n",
    "all_results.append((sampler[0]+\"_\"+BASE_NAME, exp_metrics, model_results))\n",
    "\n",
    "log(\"basic, tpot, {0}, {1}\".format(sampler[0], time.time()-start), 'Basic_Tpot.log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1.6 Baseline - Default Settings - Over sampling - 50% of majority size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "start = time.time()\n",
    "\n",
    "sampler = ('ROS 2:1', RandomOverSampler(random_state=RANDOM_STATE, sampling_strategy = 1/2))\n",
    "\n",
    "exp_metrics, model_results = perform_experiment(X_train, X_test, y_train, y_test, classifiers, sampler, 1, \\\n",
    "                                                cv_iter=CV_ITER, cat_col=cat_col)\n",
    "\n",
    "all_metrics = all_metrics.append(exp_metrics)\n",
    "all_results.append((sampler[0]+\"_\"+BASE_NAME, exp_metrics, model_results))\n",
    "\n",
    "log(\"basic, tpot, {0}, {1}\".format(sampler[0], time.time()-start), 'Basic_Tpot.log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1.7 Baseline Default Settings SMOTE-NC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "start = time.time()\n",
    "\n",
    "sampler = ('SMOTE_NC', SMOTENC(random_state=RANDOM_STATE, categorical_features=[0,1,2,3,4,5,6,7,12,13], n_jobs=8))\n",
    "\n",
    "## Keep the following, essentially dropping the dt columns\n",
    "cols = ['is_churn', 'city', 'bd', 'registered_via', 'total_order',\n",
    "       'payment_method_id_mode', 'payment_method_id_count',\n",
    "       'payment_plan_days_mode', 'payment_plan_days_mean',\n",
    "       'plan_list_price_mean', 'plan_lifetime_value', 'actual_amount_mean',\n",
    "       'total_actual_amount', 'is_auto_renew_mode', 'cancel_times']\n",
    "\n",
    "exp_metrics, model_results = perform_experiment(X_train, X_test, y_train, y_test, classifiers, sampler, 1, \\\n",
    "                                                cv_iter=CV_ITER, cat_col=cat_col)\n",
    "\n",
    "all_metrics = all_metrics.append(exp_metrics)\n",
    "all_results.append((sampler[0]+\"_\"+BASE_NAME, exp_metrics, model_results))\n",
    "\n",
    "log(\"basic, tpot, {0}, {1}\".format(sampler[0], time.time()-start), 'Basic_Tpot.log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics.sort_values('aucroc', ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Just try an SVM \n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model_train_results = train_model(base_dataset, sampling_method = 'under', classifiers = [('SGDClassifier', SGDClassifier(loss='log'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Print the feature importance \n",
    "\n",
    "feature_index = np.flip(np.argsort(model.feature_importances_), axis=0)\n",
    "ordered_features = []\n",
    "column_names = X_test.columns\n",
    "\n",
    "for i in feature_index[0:10]:\n",
    "    print(np.round(model.feature_importances_[i], 3), ' --> ', column_names[i])\n",
    "    ordered_features.append(column_names[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Print the permutation importance \n",
    "\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "\n",
    "_, X_test, _, y_test = prepare_train_test_split(model_dataset, 0)\n",
    "\n",
    "perm = PermutationImportance(model, random_state=1).fit(X_test, y_test)\n",
    "\n",
    "eli5.show_weights(perm, feature_names = X_test.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_name, model = model_train_results[1][2]\n",
    "\n",
    "for model_name, model in model_train_results[1]:\n",
    "    probs = model.predict_proba(X_test)[:, 1]\n",
    "    pr_data = plot_precision_recall(\n",
    "        y_test, probs, title='PR Curve for {0}'.format(model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = model.predict_proba(X_test)[:, 1]\n",
    "pr_data = plot_precision_recall(\n",
    "    y_test, probs, title='PR Curve for {0}'.format(model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_data = plot_roc(\n",
    "    y_test, probs, title='ROC Curve for {0}'.format(model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(plt.style.available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Original Data distribution\")\n",
    "print(model_dataset['is_churn'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display new class counts\n",
    "print('Sci-Kit Learn : resample : Down Sampled data set')\n",
    "train_downsample = undersampled_dataset(model_dataset, 'is_churn')\n",
    "\n",
    "print(train_downsample['is_churn'].value_counts())\n",
    "print(\"Num records = \", train_downsample.shape[0])\n",
    "train_downsample.is_churn.value_counts().plot(kind='bar', title='Count (target)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display new class counts\n",
    "print('Sci-Kit Learn : resample : Up Sampled data set')\n",
    "train_upsample = oversampled_dataset(model_dataset, 'is_churn')\n",
    "\n",
    "print(train_upsample['is_churn'].value_counts())\n",
    "print(\"Num records = \", train_upsample.shape[0])\n",
    "train_upsample.is_churn.value_counts().plot(kind='bar', title='Count (target)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "probs = model.predict_proba(X_test)[:, 1]\n",
    "pr_data = plot_precision_recall(\n",
    "    y_test, probs, title='Precision-Recall Curve for Random Forest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_above = pr_data.loc[pr_data['precision'] >= 0.25].copy()\n",
    "precision_above.sort_values('recall', ascending=False, inplace=True)\n",
    "precision_above.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "threshold_required = 0.5\n",
    "# Make predictions where probability is above threshold\n",
    "preds = np.zeros(len(y_test))\n",
    "preds[probs >= threshold_required] = 1\n",
    "\n",
    "# Make and plot confusion matrix\n",
    "cm = confusion_matrix(y_test, preds)\n",
    "plot_confusion_matrix(cm, classes=['No Churn', 'Churn'],\n",
    "                      title='Churn Confusion Matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi = pd.DataFrame({'importance': model.feature_importances_}, index=model_dataset.iloc[:, 1:].columns).\\\n",
    "    sort_values('importance', ascending=False)\n",
    "fi.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
