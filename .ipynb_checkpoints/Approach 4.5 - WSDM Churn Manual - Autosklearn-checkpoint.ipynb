{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "## @see https://www.kaggle.com/toorkp/churn-wsdm/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "init_cell": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "init_cell": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anaconda/lib/python3.7/site-packages/pyparsing.py:2927: FutureWarning: Possible set intersection at position 3\n",
      "  self.re = re.compile( self.reString )\n",
      "/home/anaconda/lib/python3.7/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import gc; gc.enable()\n",
    "import time\n",
    "import sys\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_curve, auc, confusion_matrix, f1_score, log_loss, confusion_matrix\n",
    "\n",
    "from collections import Counter\n",
    "from numpy.random import RandomState\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "pd.options.display.float_format = \"{:.2f}\".format\n",
    "np.set_printoptions(precision=4)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "sys.path.append('modules')\n",
    "\n",
    "from shared_functions import *\n",
    "import pickle\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Shape: (600803, 17) (600803,)\n",
      "Train Shape: (257487, 17) (257487,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>bd</th>\n",
       "      <th>gender</th>\n",
       "      <th>registered_via</th>\n",
       "      <th>membership_months</th>\n",
       "      <th>total_order</th>\n",
       "      <th>payment_method_id_mode</th>\n",
       "      <th>payment_method_id_count</th>\n",
       "      <th>payment_plan_days_mode</th>\n",
       "      <th>payment_plan_days_mean</th>\n",
       "      <th>plan_list_price_mean</th>\n",
       "      <th>plan_lifetime_value</th>\n",
       "      <th>actual_amount_mean</th>\n",
       "      <th>total_actual_amount</th>\n",
       "      <th>is_auto_renew_mode</th>\n",
       "      <th>cancel_times</th>\n",
       "      <th>transaction_date_delta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "      <td>3</td>\n",
       "      <td>38</td>\n",
       "      <td>6</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>10.00</td>\n",
       "      <td>49.67</td>\n",
       "      <td>298.00</td>\n",
       "      <td>149.00</td>\n",
       "      <td>894.00</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>700.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>20</td>\n",
       "      <td>male</td>\n",
       "      <td>3</td>\n",
       "      <td>38</td>\n",
       "      <td>5</td>\n",
       "      <td>38</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>25.40</td>\n",
       "      <td>125.40</td>\n",
       "      <td>627.00</td>\n",
       "      <td>125.40</td>\n",
       "      <td>627.00</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>344.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>18</td>\n",
       "      <td>male</td>\n",
       "      <td>3</td>\n",
       "      <td>38</td>\n",
       "      <td>18</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>30.00</td>\n",
       "      <td>149.00</td>\n",
       "      <td>2682.00</td>\n",
       "      <td>149.00</td>\n",
       "      <td>2682.00</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>530.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>7</td>\n",
       "      <td>37</td>\n",
       "      <td>19</td>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>25.63</td>\n",
       "      <td>125.47</td>\n",
       "      <td>2384.00</td>\n",
       "      <td>141.16</td>\n",
       "      <td>2682.00</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>413.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>35</td>\n",
       "      <td>female</td>\n",
       "      <td>7</td>\n",
       "      <td>37</td>\n",
       "      <td>24</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>26.25</td>\n",
       "      <td>105.38</td>\n",
       "      <td>2529.00</td>\n",
       "      <td>123.17</td>\n",
       "      <td>2956.00</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>586.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  city  bd   gender registered_via  membership_months  total_order  \\\n",
       "0    5  28     male              3                 38            6   \n",
       "1   13  20     male              3                 38            5   \n",
       "2   13  18     male              3                 38           18   \n",
       "3    1   0  unknown              7                 37           19   \n",
       "4   13  35   female              7                 37           24   \n",
       "\n",
       "   payment_method_id_mode  payment_method_id_count  payment_plan_days_mode  \\\n",
       "0                      31                        2                       0   \n",
       "1                      38                        3                      30   \n",
       "2                      38                        1                      30   \n",
       "3                      41                        2                      30   \n",
       "4                      41                        1                      30   \n",
       "\n",
       "   payment_plan_days_mean  plan_list_price_mean  plan_lifetime_value  \\\n",
       "0                   10.00                 49.67               298.00   \n",
       "1                   25.40                125.40               627.00   \n",
       "2                   30.00                149.00              2682.00   \n",
       "3                   25.63                125.47              2384.00   \n",
       "4                   26.25                105.38              2529.00   \n",
       "\n",
       "   actual_amount_mean  total_actual_amount  is_auto_renew_mode  cancel_times  \\\n",
       "0              149.00               894.00                True             1   \n",
       "1              125.40               627.00               False             0   \n",
       "2              149.00              2682.00               False             0   \n",
       "3              141.16              2682.00                True             3   \n",
       "4              123.17              2956.00                True             2   \n",
       "\n",
       "   transaction_date_delta  \n",
       "0                  700.00  \n",
       "1                  344.00  \n",
       "2                  530.00  \n",
       "3                  413.00  \n",
       "4                  586.00  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the pre-split data\n",
    "\n",
    "store = pd.HDFStore('/home/dissertation/data/feat_eng_abt_split.h5')\n",
    "X_train, X_test, y_train, y_test = store['X_train'], store['X_test'], store['y_train'], store['y_test']\n",
    "store.close()\n",
    "\n",
    "# Drop msno from the dataset\n",
    "X_train.drop(['msno', 'registration_init_time', 'registration_init_time_dt'], inplace=True, axis=1, errors='ignore')\n",
    "X_test.drop(['msno', 'registration_init_time', 'registration_init_time_dt'], inplace=True, axis=1, errors='ignore')\n",
    "\n",
    "print(\"Train Shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Train Shape:\", X_test.shape, y_test.shape)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42 \n",
    "CV_ITER = None\n",
    "SCORING_METRIC = autosklearn.metrics.recall\n",
    "BASE_NAME = \"askbasic_\" + str(CV_ITER) + \"cv_\" + str(SCORING_METRIC)\n",
    "N_JOBS = 2\n",
    "## Time periods to train for in minutes\n",
    "# TIME_PERIODS = [0.25, 0.5, 1, 2, 3, 4]\n",
    "TIME_PERIODS = [10, 15, 20, 25, 30, 35, 40, 45, 50]#, 55, 60]\n",
    "\n",
    "## Set the list of the categorical columns in the dataset\n",
    "cat_col = ['city', 'gender', 'registered_via', 'payment_method_id_mode']\n",
    "\n",
    "df_cols = X_train.columns\n",
    "feat_types =  ['Categorical' if col in cat_col else 'Numerical' for col in df_cols]\n",
    "\n",
    "classifiers = []\n",
    "\n",
    "## Each entry in the list is a Tuple of\n",
    "##   [ModelName, Model, HyperParams, ScoringMetric]    \n",
    "for period in TIME_PERIODS:\n",
    "    classifiers.append(\n",
    "        ('ASKLEARN_{}_'.format(str(period)) + BASE_NAME,                        ## ModelName\n",
    "         autosklearn.classification.AutoSklearnClassifier(                      ## Model  \n",
    "                time_left_for_this_task=int(60*period), \n",
    "                n_jobs=N_JOBS,\n",
    "                include_estimators=[\"random_forest\", \"decision_tree\", \"adaboost\", \"gaussian_nb\",\n",
    "                                    \"liblinear_svc\", \"xgradient_boosting\"], \n",
    "                exclude_estimators=None,\n",
    "                include_preprocessors=[\"no_preprocessing\", ], \n",
    "                exclude_preprocessors=None,\n",
    "                ml_memory_limit = 3072*9), \n",
    "         {},                                                                    ## HyperParams\n",
    "         SCORING_METRIC)                                                        ## ScoringMetric \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics = pd.DataFrame()\n",
    "all_results = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('/tmp/manask_all_metrics.pickle', 'rb') as f:\n",
    "#     # The protocol version used is detected automatically, so we do not\n",
    "#     # have to specify it.\n",
    "#     all_metrics = pickle.load(f)\n",
    "\n",
    "# with open('/tmp/manask_all_results.pickle', 'rb') as f:\n",
    "#     # The protocol version used is detected automatically, so we do not\n",
    "#     # have to specify it.\n",
    "#     all_results = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Write (overwrite) the file to store the experiment results\n",
    "# with open('/tmp/manask_all_metrics.pickle', 'wb') as f:\n",
    "#     # Pickle the 'data' dictionary using the highest protocol available.\n",
    "#     print(\"Writing results to\", f.name)\n",
    "#     pickle.dump(all_metrics, f, pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "# # Write (overwrite) the file to store the experiment results\n",
    "# with open('/tmp/manask_all_results.pickle', 'wb') as f:\n",
    "#     # Pickle the 'data' dictionary using the highest protocol available.\n",
    "#     print(\"Writing results to\", f.name)\n",
    "#     pickle.dump(all_results, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1.1 Baseline - Default Settings - No sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "start = time.time()\n",
    "\n",
    "sampler = ('None', DummySampler())\n",
    "\n",
    "exp_metrics, model_results = perform_experiment(X_train, X_test, y_train, y_test, classifiers, sampler, 1, \\\n",
    "                                                cv_iter=CV_ITER, cat_col=cat_col, auto_ml = False)\n",
    "\n",
    "all_metrics = all_metrics.append(exp_metrics)\n",
    "all_results.append((sampler[0]+\"_\"+BASE_NAME, exp_metrics, model_results))\n",
    "\n",
    "log(\"basic, autosklearn, {0}, {1}\".format(sampler[0], time.time()-start), 'Basic_Autosklearn.log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics[['sampling_method']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics[['label','sampling_method']].groupby(['sampling_method']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1.2 Baseline - Default Settings - Oversampled training set 100%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "start = time.time()\n",
    "\n",
    "sampler = ('ROS 1:1', RandomOverSampler(random_state=RANDOM_STATE))\n",
    "\n",
    "exp_metrics, model_results = perform_experiment(X_train, X_test, y_train, y_test, classifiers, sampler, 1, \\\n",
    "                                                cv_iter=CV_ITER, cat_col=cat_col, auto_ml = False)\n",
    "\n",
    "all_metrics = all_metrics.append(exp_metrics)\n",
    "all_results.append((sampler[0]+\"_\"+BASE_NAME, exp_metrics, model_results))\n",
    "\n",
    "log(\"basic, autosklearn, {0}, {1}\".format(sampler[0], time.time()-start), 'Basic_Autosklearn.log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1.3 Baseline - Default Settings - Undersampled training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "start = time.time()\n",
    "\n",
    "sampler = ('RUS 1:1', RandomUnderSampler(random_state=RANDOM_STATE))\n",
    "\n",
    "exp_metrics, model_results = perform_experiment(X_train, X_test, y_train, y_test, classifiers, sampler, 1, \\\n",
    "                                                cv_iter=CV_ITER, cat_col=cat_col, auto_ml = False)\n",
    "\n",
    "all_metrics = all_metrics.append(exp_metrics)\n",
    "all_results.append((sampler[0]+\"_\"+BASE_NAME, exp_metrics, model_results))\n",
    "\n",
    "log(\"basic, autosklearn, {0}, {1}\".format(sampler[0], time.time()-start), 'Basic_Autosklearn.log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sys.getsizeof(model)\n",
    "# model = all_results[0][2][0][-1]\n",
    "# print(model.sprint_statistics())\n",
    "# print(model.show_models())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1.4 Baseline - Default Settings - Over sampling - 33% of majority size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "start = time.time()\n",
    "\n",
    "sampler = ('ROS 3:1', RandomOverSampler(random_state=RANDOM_STATE, sampling_strategy = 1/3))\n",
    "\n",
    "exp_metrics, model_results = perform_experiment(X_train, X_test, y_train, y_test, classifiers, sampler, 1, \\\n",
    "                                                cv_iter=CV_ITER, cat_col=cat_col, auto_ml = False)\n",
    "\n",
    "all_metrics = all_metrics.append(exp_metrics)\n",
    "all_results.append((sampler[0]+\"_\"+BASE_NAME, exp_metrics, model_results))\n",
    "\n",
    "log(\"basic, autosklearn, {0}, {1}\".format(sampler[0], time.time()-start), 'Basic_Autosklearn.log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RUS 1:1    11\n",
       "ROS 3:1     9\n",
       "None        9\n",
       "ROS 1:1     9\n",
       "Name: sampling_method, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_metrics.sampling_method.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics.sort_values(['balanced_accuracy', 'recall'], ascending=[False, False]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1.5 Baseline - Default Settings - Over sampling - 66% of majority size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "start = time.time()\n",
    "\n",
    "sampler = ('ROS 3:2', RandomOverSampler(random_state=RANDOM_STATE, sampling_strategy = 2/3))\n",
    "\n",
    "exp_metrics, model_results = perform_experiment(X_train, X_test, y_train, y_test, classifiers, sampler, 1, \\\n",
    "                                                cv_iter=CV_ITER, cat_col=cat_col, auto_ml = False)\n",
    "\n",
    "all_metrics = all_metrics.append(exp_metrics)\n",
    "all_results.append((sampler[0]+\"_\"+BASE_NAME, exp_metrics, model_results))\n",
    "\n",
    "log(\"basic, autosklearn, {0}, {1}\".format(sampler[0], time.time()-start), 'Basic_Autosklearn.log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1.6 Baseline - Default Settings - Over sampling - 50% of majority size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "start = time.time()\n",
    "\n",
    "sampler = ('ROS 2:1', RandomOverSampler(random_state=RANDOM_STATE, sampling_strategy = 1/2))\n",
    "\n",
    "exp_metrics, model_results = perform_experiment(X_train, X_test, y_train, y_test, classifiers, sampler, 1, \\\n",
    "                                                cv_iter=CV_ITER, cat_col=cat_col, auto_ml = False)\n",
    "\n",
    "all_metrics = all_metrics.append(exp_metrics)\n",
    "all_results.append((sampler[0]+\"_\"+BASE_NAME, exp_metrics, model_results))\n",
    "\n",
    "log(\"basic, autosklearn, {0}, {1}\".format(sampler[0], time.time()-start), 'Basic_Autosklearn.log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1.7 Baseline Default Settings SMOTE-NC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRE-SAMPLING: (600803, 17) (600803,) Counter({0: 544661, 1: 56142})\n"
     ]
    }
   ],
   "source": [
    "sampler = ('SMOTE_NC', SMOTENC(random_state=RANDOM_STATE, categorical_features=[0,1,2,3,4,5,6,7,8,13,14], n_jobs=8))\n",
    "\n",
    "X_train_t, X_test_t, y_train_t, y_test_t = \\\n",
    "    prepare_train_test_data(X_train, X_test, y_train, y_test, \n",
    "                            sampler = RandomOverSampler(random_state=RANDOM_STATE), \n",
    "                            cat_col = cat_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "start = time.time()\n",
    "sampler = ('SMOTE_NC', SMOTENC(random_state=RANDOM_STATE, categorical_features=[0,1,2,4,6,10,12], n_jobs=8))\n",
    "\n",
    "## Keep the following, essentially dropping the dt columns\n",
    "cols = ['is_churn', 'city', 'bd', 'registered_via', 'total_order',\n",
    "       'payment_method_id_mode', 'payment_method_id_count',\n",
    "       'payment_plan_days_mode', 'payment_plan_days_mean',\n",
    "       'plan_list_price_mean', 'plan_lifetime_value', 'actual_amount_mean',\n",
    "       'total_actual_amount', 'is_auto_renew_mode', 'cancel_times']\n",
    "\n",
    "exp_metrics, model_results = perform_experiment(X_train, X_test, y_train, y_test, classifiers, sampler, 1, \\\n",
    "                                                cv_iter=CV_ITER, cat_col=cat_col, auto_ml = True)\n",
    "\n",
    "all_metrics = all_metrics.append(exp_metrics)\n",
    "all_results.append((sampler[0]+\"_\"+BASE_NAME, exp_metrics, model_results))\n",
    "\n",
    "log(\"basic, autosklearn, {0}, {1}\".format(sampler[0], time.time()-start), 'Basic_Autosklearn.log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics.sort_values('recall', ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#store(all_results, 'Asklearn_Default_Undersample.pickle')\n",
    "\n",
    "# Write (overwrite) the file to store the experiment results\n",
    "with open('Manual_Asklearn_20190813.pickle', 'wb') as f:\n",
    "    # Pickle the 'data' dictionary using the highest protocol available.\n",
    "    print(\"Writing results to\", f.name)\n",
    "    pickle.dump(all_results, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Just try an SVM \n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model_train_results = train_model(base_dataset, sampling_method = 'under', classifiers = [('SGDClassifier', SGDClassifier(loss='log'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Print the feature importance \n",
    "\n",
    "feature_index = np.flip(np.argsort(model.feature_importances_), axis=0)\n",
    "ordered_features = []\n",
    "column_names = X_test.columns\n",
    "\n",
    "for i in feature_index[0:10]:\n",
    "    print(np.round(model.feature_importances_[i], 3), ' --> ', column_names[i])\n",
    "    ordered_features.append(column_names[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Print the permutation importance \n",
    "\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "\n",
    "_, X_test, _, y_test = prepare_train_test_split(model_dataset, 0)\n",
    "\n",
    "perm = PermutationImportance(model, random_state=1).fit(X_test, y_test)\n",
    "\n",
    "eli5.show_weights(perm, feature_names = X_test.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_name, model = model_train_results[1][2]\n",
    "\n",
    "for model_name, model in model_train_results[1]:\n",
    "    probs = model.predict_proba(X_test)[:, 1]\n",
    "    pr_data = plot_precision_recall(\n",
    "        y_test, probs, title='PR Curve for {0}'.format(model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = model.predict_proba(X_test)[:, 1]\n",
    "pr_data = plot_precision_recall(\n",
    "    y_test, probs, title='PR Curve for {0}'.format(model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_data = plot_roc(\n",
    "    y_test, probs, title='ROC Curve for {0}'.format(model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(plt.style.available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Original Data distribution\")\n",
    "print(model_dataset['is_churn'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display new class counts\n",
    "print('Sci-Kit Learn : resample : Down Sampled data set')\n",
    "train_downsample = undersampled_dataset(model_dataset, 'is_churn')\n",
    "\n",
    "print(train_downsample['is_churn'].value_counts())\n",
    "print(\"Num records = \", train_downsample.shape[0])\n",
    "train_downsample.is_churn.value_counts().plot(kind='bar', title='Count (target)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display new class counts\n",
    "print('Sci-Kit Learn : resample : Up Sampled data set')\n",
    "train_upsample = oversampled_dataset(model_dataset, 'is_churn')\n",
    "\n",
    "print(train_upsample['is_churn'].value_counts())\n",
    "print(\"Num records = \", train_upsample.shape[0])\n",
    "train_upsample.is_churn.value_counts().plot(kind='bar', title='Count (target)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "probs = model.predict_proba(X_test)[:, 1]\n",
    "pr_data = plot_precision_recall(\n",
    "    y_test, probs, title='Precision-Recall Curve for Random Forest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_above = pr_data.loc[pr_data['precision'] >= 0.25].copy()\n",
    "precision_above.sort_values('recall', ascending=False, inplace=True)\n",
    "precision_above.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "threshold_required = 0.5\n",
    "# Make predictions where probability is above threshold\n",
    "preds = np.zeros(len(y_test))\n",
    "preds[probs >= threshold_required] = 1\n",
    "\n",
    "# Make and plot confusion matrix\n",
    "cm = confusion_matrix(y_test, preds)\n",
    "plot_confusion_matrix(cm, classes=['No Churn', 'Churn'],\n",
    "                      title='Churn Confusion Matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi = pd.DataFrame({'importance': model.feature_importances_}, index=model_dataset.iloc[:, 1:].columns).\\\n",
    "    sort_values('importance', ascending=False)\n",
    "fi.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
